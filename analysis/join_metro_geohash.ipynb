{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beaa81e9-9dc6-48c5-9a05-1ee0e55af9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from shapely import geometry\n",
    "from polygeohasher import polygeohasher\n",
    "import geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23842f4a-b207-40e9-8408-9a7e50dcc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geoh_stops = pd.read_csv('../data/activity_2023-04-01_2024-03-31.csv')\n",
    "gdf_met = gpd.read_file('../data/metro_regions.geojson')\n",
    "\n",
    "EXCLUDE_REGIONS = [\n",
    "    \"Ottawa - Gatineau (Ontario part / partie de l'Ontario) (B)\", \n",
    "    'Ottawa - Gatineau (partie du Québec / Quebec part) (B)',\n",
    "    'San Juan-Bayamón-Caguas, PR Metro Area',\n",
    "    'Arecibo, PR Metro Area',\n",
    "    'Aguadilla-Isabela, PR Metro Area',\n",
    "    'Ponce, PR Metro Area',\n",
    "]\n",
    "gdf_met = gdf_met.drop(gdf_met[gdf_met.name.isin(EXCLUDE_REGIONS)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53989ca1-fb56-4a67-a5cc-078d7c65ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1889674/2954203109.py:1: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf_cent = gdf_met.set_geometry(gdf_met.centroid)\n"
     ]
    }
   ],
   "source": [
    "gdf_cent = gdf_met.set_geometry(gdf_met.centroid)\n",
    "gdf_cent.to_file('../data/metro_regions_centroids.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50aad9-f086-45ab-abd8-921ae5987b69",
   "metadata": {},
   "source": [
    "Generate geohashes for each metro region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c89861-d709-4da4-b301-0b7411bd2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgh = polygeohasher.Polygeohasher(gdf_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963989cd-0cbf-40e6-874a-c3207a17f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_GEOHASH_LEVEL = 6\n",
    "df_init = pgh.create_geohash_list(INPUT_GEOHASH_LEVEL, inner=False)  # 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b117985b-d74f-4999-8464-65f1dfc7813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_geo = pgh.geohashes_to_geometry(df_init, \"geohash_list\")  # 2-3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53108402-ea38-4ea5-8c57-a465766964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intersect_area(gdf, row):\n",
    "    \"\"\" Given the region polygons (gdf) and the geohash row (row), return the\n",
    "    area of the intersection. \n",
    "    \"\"\"\n",
    "    region_name = row['name']\n",
    "    region_poly = gdf.loc[gdf['name'] == region_name]['geometry'].values[0]\n",
    "    return row['geometry'].intersection(region_poly).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a026a475-b861-4701-bc30-9bf495080d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 4017916/4017916 [29:15<00:00, 2288.39it/s]\n"
     ]
    }
   ],
   "source": [
    "gdf_geo['intersect_area'] = gdf_geo.progress_apply(lambda x: compute_intersect_area(gdf_met, x), axis=1)  # 30 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c89d67-bdc5-432a-bac8-6d9f65948142",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_geo = gdf_geo.sort_values(by=['intersect_area'], ascending=False).drop_duplicates(subset=['geohash_list'])\n",
    "gdf_geo = gdf_geo.sort_values(by=['name', 'geohash_list'])\n",
    "gdf_geo = gdf_geo.drop(['intersect_area', 'population'], axis=1)\n",
    "gdf_geo = gdf_geo.rename(columns={\"geohash_list\": \"geohash\"})\n",
    "df_geo = pd.DataFrame(gdf_geo.drop(columns='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f33580-cb95-4854-9312-39ac3bc3f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.to_csv('../data/metro_region_geohashes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54caf4bf-e72d-463c-8f9a-e0185ee647ca",
   "metadata": {},
   "source": [
    "Link the activity data to the metro regions by geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b9fdc4-9734-4911-9b66-7408bd63d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_TO_PROVINCE = {\n",
    "    'Toronto': 'ON',\n",
    "    'Montréal': 'QC',\n",
    "    'Vancouver': 'BC',\n",
    "    'Ottawa - Gatineau': 'ON-QC',\n",
    "    'Calgary': 'AB',\n",
    "    'Edmonton': 'AB',\n",
    "    'Québec': 'QC',\n",
    "    'Winnipeg': 'MB',\n",
    "    'Hamilton': 'ON',\n",
    "    'Kitchener - Cambridge - Waterloo': 'ON',\n",
    "    'London': 'ON',\n",
    "    'Halifax': 'NS',\n",
    "    'St. Catharines - Niagara': 'ON',\n",
    "    'Windsor': 'ON',\n",
    "    'Oshawa': 'ON',\n",
    "    'Victoria': 'BC',\n",
    "    'Saskatoon': 'SK',\n",
    "    'Regina': 'SK',\n",
    "    'Sherbrooke': 'QC',\n",
    "    'Kelowna': 'BC',\n",
    "    'Barrie': 'ON',\n",
    "    \"St. John's\": 'NL',\n",
    "    'Abbotsford - Mission': 'BC',\n",
    "    'Kingston': 'ON',\n",
    "    'Greater Sudbury / Grand Sudbury': 'ON',\n",
    "    'Guelph': 'ON',\n",
    "    'Saguenay': 'QC',\n",
    "    'Trois-Rivières': 'QC',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd93171-3144-47f9-ad4e-6d22ed5888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohash_to_polygon(geo):\n",
    "    \"\"\"\n",
    "    https://github.com/rohitsinghsalyan/polygeohasher/blob/master/polygeohasher/polygon_geohash_convertor.py\n",
    "    :param geo: String that represents the geohash.\n",
    "    :return: Returns a Shapely's Polygon instance that represents the geohash.\n",
    "    \"\"\"\n",
    "    lat_centroid, lng_centroid, lat_offset, lng_offset = geohash.decode_exactly(geo)\n",
    "\n",
    "    corner_1 = (lat_centroid - lat_offset, lng_centroid - lng_offset)[::-1]\n",
    "    corner_2 = (lat_centroid - lat_offset, lng_centroid + lng_offset)[::-1]\n",
    "    corner_3 = (lat_centroid + lat_offset, lng_centroid + lng_offset)[::-1]\n",
    "    corner_4 = (lat_centroid + lat_offset, lng_centroid - lng_offset)[::-1]\n",
    "\n",
    "    return geometry.Polygon([corner_1, corner_2, corner_3, corner_4, corner_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8288d4-84e6-4b12-b1d1-24c8bc78c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = pd.read_csv('../data/metro_region_geohashes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5a8642-e50d-4f73-a2dd-e108322d1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geoh_stops = df_geoh_stops.rename(columns={\"geohash6\": \"geohash\"})\n",
    "df_region_geo_stops = pd.merge(df_geo, df_geoh_stops, on=\"geohash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c57f173-0e4b-44ee-9be7-60064c9d0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stops = df_region_geo_stops['total_stops'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f595e6-7d09-4329-a338-8cee56553ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▊   | 271/294 [08:39<00:26,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "metro_regions = gdf_met['name'].unique()\n",
    "for region in tqdm(metro_regions):\n",
    "    df_subset = df_region_geo_stops[df_region_geo_stops['name'] == region]\n",
    "    df_subset = df_subset.drop(columns=['name'])\n",
    "\n",
    "    subset_stops = df_subset['total_stops'].sum()\n",
    "    df_subset['prop_total_stops'] = df_subset['total_stops'] / total_stops\n",
    "    df_subset['prop_subset_stops'] = df_subset['total_stops'] / subset_stops\n",
    "    df_subset = df_subset.drop(columns=['total_stops'])\n",
    "    \n",
    "    # # Unified Ottawa region only\n",
    "    # if region in EXCLUDE_REGIONS:\n",
    "    #     continue\n",
    "\n",
    "    region = region.replace(\" Metro Area\", \"\")\n",
    "    region = region.replace(\" (B)\", \"\")\n",
    "\n",
    "    # Canadian province codes\n",
    "    if \",\" not in region:  \n",
    "        region = f\"{region}, {CITY_TO_PROVINCE[region]}\"\n",
    "\n",
    "    # Louisville and Greater Sudbury\n",
    "    if '/' in region:\n",
    "        s = region.split(',')\n",
    "        s[0] = s[0].split('/')[0].strip()\n",
    "        region = \",\".join(s)\n",
    "\n",
    "    df_subset['geometry'] = df_subset.apply(lambda x: geohash_to_polygon(x['geohash']), axis=1)\n",
    "    gdf_subset = gpd.GeoDataFrame(df_subset)\n",
    "\n",
    "    gdf_subset.to_file(f'../data/metro_region_geohash_stops/{region}.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
